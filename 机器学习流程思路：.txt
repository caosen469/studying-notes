机器学习流程思路：

原始数据 --- (数据预处理---特征处理---特征转换)---预测---得到结果
            [特征处理，特征处理也常采用机器学习的方法]    [浅层学习]

'数据预处理': 去除噪声，比如文本数据中，去掉停用词
'特征处理': 从原始的数据中提取出一些有效的特征
'特征转换': 对特征处理得到的特征进行一些加工，比如'升维'和'降维'；
    '降维'：特张抽取，特征选择；   
        (个人理解：特征抽取，比如颜色分类，如果使用one-hat向量表示的方法，一开始我们有
        红黄蓝绿四种颜色，就是四个维度，然后现在我们只使用红黄蓝三个特征，则维度就从四维
        变为了三维)
        (另一种降维方法就是映射吧，比如把'红黄蓝绿青蓝紫'这个七维空间，映射成RGB三维空间)
    常用的特征转换方法：'主成分分析' (Principle components analysis) and '线性判别分析' (Linear Discriminent Analysis)
    *wikipedia page*

*很多机器学习算法，亦即最后的预测上所用到的训练模型，其实性能差不了太多，最关键的因素还是之前的
'Feature Engineering': (数据预处理---特征处理---特征转换)


1.3 表示学习
有了之前的铺垫，我们知道最关键的其实是特征工程而不是模型的选择，
'何为表示学习'：
    '何为表示': 原始数据--->有效的特征，这个'有效的特征'其实就是'表示'
'表示学习':有一种算法，可以自动地学习出有效的特征，并挺高最终机器学习模型的性能，那么就可以乘坐表示学习。
    (i.e.:比如图像识别，我们的输入就是原始图片，顶多经过裁剪等简单处理，把这些原始图片的RGB表示输入到卷积神经网络中，然后进行学习，我们输入的基本就是原始数据，是各层的神经元自己在学习特征) 

'语义鸿沟'：比如一辆红色的法拉利，和一辆银色的五菱宏光的照片，站在人类的角度，由于我们高层次的抽象理解能力，我们可以判断出来他们是一类东西。但是如果从底层特征的角度(比如pixel)的角度理解，可能红色法拉利跟一个红色的猫，相对于银色的红菱红光而言更像是一类事物。🐱。这就是语义鸿沟，人类的理解是基于高层次特征的(车的特征)，而电脑算法的理解是基于底层特征的(照片的rgb像素)，因此直接基于底层特征进行学习较为困难。我们也很难告诉计算机，什么叫做有四个轱辘。

1.3.1 局部表示和分布式表示

1.4 深度学习
